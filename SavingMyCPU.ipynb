{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Stochastic Gradient Descent Convolution Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTHvbJGUMTEw"
      },
      "outputs": [],
      "source": [
        "!unzip /Training_Data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Da8--qEhIl9K"
      },
      "outputs": [],
      "source": [
        "# This will be the Neural Network Script\n",
        "# Cites : https://keras.io/examples/vision/image_classification_from_scratch/\n",
        "# Depends on : pydot and Graphviz\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "image_size = (100, 100) #More power needed, but more accuracy gained.\n",
        "batch_size = 32\n",
        "\n",
        "DataSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Training_Data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "Validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Training_Data\",\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "# This is a method useful for our use-case where I doubt I can\n",
        "# capture a data set of 10,000.\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomFlip(\"horizontal\"),\n",
        "     layers.RandomRotation(0.1),\n",
        "     layers.RandomFlip(\"vertical\"),\n",
        "     ]\n",
        ")\n",
        "\n",
        "\n",
        "# # For CPU training\n",
        "# augmented_train_ds = DataSet.map(\n",
        "#     lambda x, y: (data_augmentation(x, training=True), y)\n",
        "# )\n",
        "\n",
        "\n",
        "# Prevents I/O issues\n",
        "train_ds = DataSet.prefetch(buffer_size=32)\n",
        "val_ds = Validation.prefetch(buffer_size=32)\n",
        "\n",
        "\n",
        "# Directly Cites : https://keras.io/examples/vision/image_classification_from_scratch/\n",
        "def NModel(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1.0 / 255)(x)\n",
        "    # x = layers.Conv2D(1024,3, strides = 2, padding= \"same\")(x) my computer cannot.\n",
        "    x = layers.Conv2D(128, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(128, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    previous_block_activation = x\n",
        "\n",
        "    for size in [128, 256, 512, 1024]:\n",
        "        # Changed to ELU\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        # Remains RELU\n",
        "        x = layers.Activation(\"relu\")(x)\n",
        "        x = layers.SeparableConv2D(size, 3, padding=\"same\")(x)\n",
        "        x = layers.BatchNormalization()(x)\n",
        "\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)  # Key for noisy images, use more than once?\n",
        "\n",
        "        # Residual? TODO : Look up for comprehension\n",
        "        residual = layers.Conv2D(size, 1, strides=2, padding=\"same\")(\n",
        "            previous_block_activation\n",
        "        )\n",
        "\n",
        "        x = layers.add([x, residual])\n",
        "        previous_block_activation = x\n",
        "\n",
        "    # TODO : Look up for comprehension\n",
        "    x = layers.SeparableConv2D(128, 3, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"sigmoid\"\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = NModel(input_shape=image_size + (3,), num_classes=2)\n",
        "keras.utils.plot_model(model, show_shapes=True)\n",
        "\n",
        "epochs = 5  # over-fitting?\n",
        "callbacks = [keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"), ]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(1e-3),\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")\n",
        "\n",
        "model.fit(DataSet, epochs=epochs, callbacks=callbacks, validation_data=Validation)\n",
        "\n",
        "img = keras.preprocessing.image.load_img(\n",
        "    \"Training_Data/sample-18255214-317-69.png\", target_size=image_size\n",
        "    # Test image is of a coffee cup with my name on it from fall of 2020.\n",
        ")\n",
        "\n",
        "img_array = keras.preprocessing.image.img_to_array(img)\n",
        "img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "\n",
        "predictions = model.predict(img_array)\n",
        "score = predictions[0]\n",
        "\n",
        "print(\"This image is %.2f percent your coffee.\" % (100 * (score)))\n",
        "\n",
        "\n",
        "def main():\n",
        "    print(\"Nothing broke before here, this is exciting\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
