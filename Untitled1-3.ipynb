{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!unzip /Training_Data.zip"
      ],
      "metadata": {
        "id": "YTHvbJGUMTEw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Da8--qEhIl9K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd8ff9c6-692f-4d6a-a2b0-9973179e4736"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 169 files belonging to 1 classes.\n",
            "Using 136 files for training.\n",
            "Found 169 files belonging to 1 classes.\n",
            "Using 16 files for validation.\n",
            "Please Enter 1 for compile 2 for test1\n",
            "Epoch 1/10\n",
            "5/5 [==============================] - 108s 18s/step - loss: 0.6239 - accuracy: 0.7574 - val_loss: 0.4876 - val_accuracy: 1.0000\n",
            "Epoch 2/10\n",
            "5/5 [==============================] - 94s 17s/step - loss: 0.4648 - accuracy: 0.9338 - val_loss: 0.3504 - val_accuracy: 1.0000\n",
            "Epoch 3/10\n",
            "5/5 [==============================] - 100s 19s/step - loss: 0.3306 - accuracy: 0.9853 - val_loss: 0.2354 - val_accuracy: 1.0000\n",
            "Epoch 4/10\n",
            "5/5 [==============================] - 95s 17s/step - loss: 0.2571 - accuracy: 0.9779 - val_loss: 0.1559 - val_accuracy: 1.0000\n",
            "Epoch 5/10\n",
            "5/5 [==============================] - 93s 17s/step - loss: 0.1954 - accuracy: 0.9191 - val_loss: 0.1088 - val_accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "5/5 [==============================] - 94s 17s/step - loss: 0.1233 - accuracy: 0.9926 - val_loss: 0.0737 - val_accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "5/5 [==============================] - 95s 17s/step - loss: 0.1043 - accuracy: 0.9779 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "5/5 [==============================] - 94s 17s/step - loss: 0.0665 - accuracy: 1.0000 - val_loss: 0.0387 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "5/5 [==============================] - 95s 18s/step - loss: 0.0583 - accuracy: 0.9853 - val_loss: 0.0311 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "5/5 [==============================] - 94s 17s/step - loss: 0.0658 - accuracy: 0.9926 - val_loss: 0.0225 - val_accuracy: 1.0000\n"
          ]
        }
      ],
      "source": [
        "# This will be the Neural Network Script\n",
        "# Cites : https://keras.io/examples/vision/image_classification_from_scratch/\n",
        "# Cites : https://www.tensorflow.org/tutorials/images/cnn\n",
        "# Depends on : pydot and Graphviz\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "image_size = (100, 100) #More power needed, but more accuracy gained.\n",
        "batch_size = 32\n",
        "\n",
        "DataSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Training_Data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "Validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Training_Data\",\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "# This is a method useful for our use-case where I doubt I can\n",
        "# capture a data set of 10,000.\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomFlip(\"horizontal\"),\n",
        "     layers.RandomRotation(0.1),\n",
        "     layers.RandomFlip(\"vertical\"),\n",
        "     ]\n",
        ")\n",
        "\n",
        "\n",
        "# # For CPU training\n",
        "# augmented_train_ds = DataSet.map(\n",
        "#     lambda x, y: (data_augmentation(x, training=True), y)\n",
        "# )\n",
        "\n",
        "\n",
        "# Prevents I/O issues\n",
        "train_ds = DataSet.prefetch(buffer_size=32)\n",
        "val_ds = Validation.prefetch(buffer_size=32)\n",
        "\n",
        "\n",
        "# Directly Cites : https://keras.io/examples/vision/image_classification_from_scratch/\n",
        "def NModel(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.SeparableConv2D(128, 3, padding=\"same\")(x)\n",
        "\n",
        "    x = layers.Conv2D(2, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(4, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(16, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(1024, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    for i in range(1,100):\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "        layers.Dense(256, activation='softmax')\n",
        "        x = layers.Dense(10)(x)\n",
        "\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"sigmoid\"\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = NModel(input_shape=image_size + (3,), num_classes=2)\n",
        "\n",
        "def Compile() :\n",
        "    keras.utils.plot_model(model, show_shapes=True)\n",
        "    epochs = 10  # over-fitting?\n",
        "    callbacks = [keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"), ]\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.SGD(1e-3),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    model.fit(DataSet, epochs=epochs, callbacks=callbacks, validation_data=Validation)\n",
        "\n",
        "def Test():\n",
        "    img = keras.preprocessing.image.load_img(\n",
        "        \"Training_Data/sample-18255214-317-69.png\", target_size=image_size\n",
        "        # Test image is of a coffee cup with my name on it from fall of 2020.\n",
        "    )\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "    predictions = model.predict(img_array)\n",
        "    score = predictions[0]\n",
        "    print(\"This image is %.2f percent your coffee.\" % (100 * (score)))\n",
        "\n",
        "\n",
        "def main():\n",
        "    x = input(\"Please Enter 1 for compile 2 for test and 3 for both\\n\")\n",
        "    if(x == \"1\"):\n",
        "        Compile()\n",
        "    elif(x == \"2\"):\n",
        "        Test()\n",
        "    elif(x == \"3\"):\n",
        "        Compile()\n",
        "        Test()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This will be the Neural Network Script\n",
        "# Cites : https://keras.io/examples/vision/image_classification_from_scratch/\n",
        "# Cites : https://www.tensorflow.org/tutorials/images/cnn\n",
        "# Depends on : pydot and Graphviz\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "\n",
        "\n",
        "image_size = (100, 100) #More power needed, but more accuracy gained.\n",
        "batch_size = 32\n",
        "\n",
        "DataSet = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Training_Data\",\n",
        "    validation_split=0.2,\n",
        "    subset=\"training\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "Validation = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "    \"Training_Data\",\n",
        "    validation_split=0.1,\n",
        "    subset=\"validation\",\n",
        "    seed=1337,\n",
        "    image_size=image_size,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "\n",
        "# This is a method useful for our use-case where I doubt I can\n",
        "# capture a data set of 10,000.\n",
        "data_augmentation = keras.Sequential(\n",
        "    [layers.RandomFlip(\"horizontal\"),\n",
        "     layers.RandomRotation(0.1),\n",
        "     layers.RandomFlip(\"vertical\"),\n",
        "     ]\n",
        ")\n",
        "\n",
        "\n",
        "# # For CPU training\n",
        "# augmented_train_ds = DataSet.map(\n",
        "#     lambda x, y: (data_augmentation(x, training=True), y)\n",
        "# )\n",
        "\n",
        "\n",
        "# Prevents I/O issues\n",
        "train_ds = DataSet.prefetch(buffer_size=32)\n",
        "val_ds = Validation.prefetch(buffer_size=32)\n",
        "\n",
        "\n",
        "# Directly Cites : https://keras.io/examples/vision/image_classification_from_scratch/\n",
        "def NModel(input_shape, num_classes):\n",
        "    inputs = keras.Input(shape=input_shape)\n",
        "    x = data_augmentation(inputs)\n",
        "    x = layers.Rescaling(1.0 / 255)(x)\n",
        "    x = layers.SeparableConv2D(128, 3, padding=\"same\")(x)\n",
        "\n",
        "    x = layers.Conv2D(2, 3, strides=2, padding=\"same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(4, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(16, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(256, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    x = layers.Conv2D(1024, 3, padding=\"Same\")(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "\n",
        "    for i in range(1,100):\n",
        "        x = layers.MaxPooling2D(3, strides=2, padding=\"same\")(x)\n",
        "        layers.Dense(256, activation='softmax')\n",
        "        x = layers.Dense(10)(x)\n",
        "\n",
        "\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    if num_classes == 2:\n",
        "        activation = \"sigmoid\"\n",
        "        units = 1\n",
        "    else:\n",
        "        activation = \"sigmoid\"\n",
        "        units = num_classes\n",
        "\n",
        "    x = layers.Dropout(0.5)(x)\n",
        "    outputs = layers.Dense(units, activation=activation)(x)\n",
        "    return keras.Model(inputs, outputs)\n",
        "\n",
        "\n",
        "model = NModel(input_shape=image_size + (3,), num_classes=2)\n",
        "\n",
        "def Compile() :\n",
        "    keras.utils.plot_model(model, show_shapes=True)\n",
        "    epochs = 10  # over-fitting?\n",
        "    callbacks = [keras.callbacks.ModelCheckpoint(\"save_at_{epoch}.h5\"), ]\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.SGD(1e-3),\n",
        "        loss=\"binary_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    model.fit(DataSet, epochs=epochs, callbacks=callbacks, validation_data=Validation)\n",
        "\n",
        "def Test():\n",
        "    img = keras.preprocessing.image.load_img(\n",
        "        \"Training_Data/sample-18255214-317-69.png\", target_size=image_size\n",
        "        # Test image is of a coffee cup with my name on it from fall of 2020.\n",
        "    )\n",
        "    img_array = keras.preprocessing.image.img_to_array(img)\n",
        "    img_array = tf.expand_dims(img_array, 0)  # Create batch axis\n",
        "    predictions = model.predict(img_array)\n",
        "    score = predictions[0]\n",
        "    print(\"This image is %.2f percent your coffee.\" % (100 * (score)))\n",
        "\n",
        "\n",
        "def main():\n",
        "    x = input(\"Please Enter 1 for compile 2 for test and 3 for both\\n\")\n",
        "    if(x == \"1\"):\n",
        "        Compile()\n",
        "    elif(x == \"2\"):\n",
        "        Test()\n",
        "    elif(x == \"3\"):\n",
        "        Compile()\n",
        "        Test()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "MztXhwpxzgQP",
        "outputId": "5f466919-6a94-4ef7-86f0-37c1d57d7361",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 169 files belonging to 1 classes.\n",
            "Using 136 files for training.\n",
            "Found 169 files belonging to 1 classes.\n",
            "Using 16 files for validation.\n",
            "Please Enter 1 for compile 2 for test and 3 for both\n",
            "2\n",
            "This image is 50.00 percent your coffee.\n"
          ]
        }
      ]
    }
  ]
}